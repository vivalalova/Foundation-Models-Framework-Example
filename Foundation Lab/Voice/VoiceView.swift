//
//  VoiceView.swift
//  Foundation Lab
//
//  Created by Rudrank Riyam on 10/27/25.
//

import SwiftUI
import Observation

struct VoiceView: View {
    @State private var viewModel = VoiceViewModel()
    @State private var isProcessingTap = false

    var body: some View {
        Group {
            if viewModel.allPermissionsGranted {
                voiceMainView
            } else {
                PermissionRequestView(viewModel: viewModel)
            }
        }
        .onAppear {
            viewModel.checkAllPermissions()
        }
        .onChange(of: viewModel.allPermissionsGranted) { _, _ in
            // Force view update when permissions change
        }
        .task {
            await viewModel.prewarmAndGreet()
        }
        .onDisappear {
            viewModel.tearDown()
        }
    }

    private var voiceMainView: some View {
        let viewModel = self.viewModel
        return VStack(spacing: 30) {
            // Header
            VStack(alignment: .leading, spacing: 16) {
                Text("Voice")
                    .font(.largeTitle)
                    .fontWeight(.bold)
                    .foregroundStyle(.primary)

                Text("Have a conversation with AI")
                    .font(.headline)
                    .foregroundStyle(.secondary)
            }
            .padding(.horizontal)
            .frame(maxWidth: .infinity, alignment: .leading)

            Spacer()

            // Main content
            VStack(spacing: 40) {
                // Transcription display
                if !viewModel.recognizedText.isEmpty || viewModel.isListening {
                    VStack(spacing: 8) {
                        if viewModel.isListening && viewModel.partialText.isEmpty {
                            HStack(spacing: 4) {
                                ForEach(0..<3) { index in
                                    Circle()
                                        .fill(Color.primary.opacity(0.5))
                                        .frame(width: 8, height: 8)
                                        .scaleEffect(viewModel.isListening ? 1.2 : 0.8)
                                        .animation(
                                            .easeInOut(duration: 0.6)
                                            .repeatForever()
                                            .delay(Double(index) * 0.2),
                                            value: viewModel.isListening
                                        )
                                }
                            }
                            .padding()
                        } else {
                            Text(viewModel.partialText.isEmpty ? viewModel.recognizedText : viewModel.partialText)
                                .font(.title3)
                                .foregroundStyle(.primary)
                                .multilineTextAlignment(.center)
                                .padding()
                                .frame(maxWidth: 300)
                                .background(
                                    RoundedRectangle(cornerRadius: 16)
                                        .fill(Color.adaptiveBackground.opacity(0.1))
                                )
                        }
                    }
                    .transition(.asymmetric(
                        insertion: .scale(scale: 0.8).combined(with: .opacity),
                        removal: .scale(scale: 0.8).combined(with: .opacity)
                    ))
                }
            }

            Spacer()
        }
        .padding()
        .alert(
            "Error",
            isPresented: Binding(
                get: { viewModel.showError },
                set: { viewModel.showError = $0 }
            )
        ) {
            Button("OK", role: .cancel) {}
        } message: {
            Text(viewModel.errorMessage)
        }
    }

    private func toggleListening() {
        // Prevent double-tapping
        guard !isProcessingTap else { return }

        isProcessingTap = true

        defer {
            // Reset processing flag after a short delay
            Task {
                try? await Task.sleep(for: .milliseconds(500))
                isProcessingTap = false
            }
        }

        if viewModel.isListening {
            viewModel.stopListening()
        } else {
            Task {
                await viewModel.startListening()
            }
        }

        // Haptic feedback
#if os(iOS)
        let impact = UIImpactFeedbackGenerator(style: .medium)
        impact.impactOccurred()
#endif
    }
}

#Preview {
    VoiceView()
}
